# Научное описание проекта: анализ травелогов о Сибири в контексте ориентализма

Документ описывает исследовательскую платформу для цифрового анализа англоязычных травелогов о Сибири: теоретическую рамку, единицы наблюдения, формулы расчёта метрик, структуру данных и выходные артефакты. Текст предназначен для методических разделов статей и отчётов.

---

## 1. Цель и теоретическая рамка

**Цель:** выявление и квантификация паттернов репрезентации народов Сибири в травелогах — в духе исследований ориентализма (Саид) и критики имперского дискурса. Платформа позволяет измерять типы репрезентации (негативная, экзотизирующая, позитивная, нейтральная), контексты упоминаний (военные, торговые, бытовые и т.д.), эссенциализирующие конструкции и сети взаимодействий между группами.

**Теоретическая рамка:**  
- **Ориентализм:** «Восток» как конструкт западного дискурса; экзотизация и маргинализация.  
- **Репрезентация (R):** как именно группа представлена в тексте (negative, exotic, positive, neutral, uncertain).  
- **Ситуация (O):** тип дискурсивной сцены (военная, торговая, бытовая, описательная и т.д.).  
- **Эссенциализация:** конструкции вида «The X are …», «by nature», «as a race», натурализующие группу как сущность.  
- **PIRO:** разметка по полям **P**erson (этноним, канонический), **R**epresentation (тип репрезентации), **O**ccasion (ситуация); **I** (Identity/эпитеты) опционально.

---

## 2. Единица наблюдения и локаторы

**Единица наблюдения:** одно упоминание этнонима в контексте одного предложения (после фильтрации шума). Каждая такая единица получает разметку P, R, O и флаги эссенциализации; по ней считаются индексы и строятся распределения.

**Локаторы (для верификации в источнике):**  
- **O_locator (source_pointer):** `file_name#sent_idx` — имя файла и порядковый номер предложения в документе. Используется для поиска фрагмента в исходном тексте и для доказательной базы (Evidence Pack, `evidence_base.xlsx`).  
- **O_scene:** тип ситуации (everyday_life, military, trade, descriptive_scene, mixed, unknown и др.) — семантическая категория, получаемая по лексикону `situation_domains.yml` (и при необходимости по LLM), а не координата в тексте.

**Агрегация по этнонимам:** все варианты написания (alias) приводятся к каноническому имени из `resources/ethnonyms.yml` (например, kirghiz, kirgis, kyrgyz → kirghiz). Подсчёты частот, индексов и профилей ведутся по каноническому имени; в отчёте отдельно показывается таблица «Варианты написания этнонимов» (alias → canonical, N и %).

---

## 3. Входные данные и предобработка

**Вход:** текстовые файлы травелогов в каталоге `data/texts/` (формат `.txt`). Имя файла используется как идентификатор документа.

**Шаги предобработки:**  
1. **Загрузка** — чтение файлов, базовая нормализация пробелов и переносов.  
2. **Очистка OCR** (опционально с SymSpell при флаге `--ocr-symspell`) — замена типичных ошибок OCR по словарю `resources/ocr_replacements.yml`.  
3. **Сегментация и морфология** — spaCy (модель `en_core_web_sm`): разбиение на предложения, токенизация, леммы, POS-теги, синтаксические зависимости. Результат: корпус документов, каждый документ — список предложений с полями `text`, `token_objects` (текст токена, лемма, POS, `head_i`, `dep` и т.д.), границы символов `start_char`, `end_char`.

Кэш предобработанного корпуса сохраняется в `output/corpus.db` (при запуске без `--from-cache` он пересоздаётся).

---

## 4. Извлечение упоминаний этнонимов

**Словарь:** `resources/ethnonyms.yml` — структура «каноническое имя → список вариантов написания» (например, `yakut: [yakut, yakuts, jakut, yacoot, ...]`).

**Режимы извлечения:**  
- **По регулярным выражениям:** для каждого канонического имени строится regex по всем вариантам (с границами слова `\b`); поиск в сыром тексте предложения.  
- **По леммам (флаг `--use-lemmas`):** токены предложения приводятся к леммам (spaCy); совпадение с каноническим множеством лемм из словаря. В этом случае в контексте и в лексиконах R/O при необходимости также используются леммы.

**Выход:** таблица упоминаний (**mentions_df**): каждая строка — одно вхождение этнонима в предложении. Поля: `file_name`, `doc_id`, `sent_idx`, `sentence_text`, `doc_position_percent`, `ethnos_norm` (каноническое имя), `ethnos_raw` (словоформа в тексте), при наличии — `context_text`, `token_objects`, `doc_sent_count`.

---

## 5. Фильтр шума

Цель: исключить из аналитической выборки колонтитулы, оглавления, повторяющиеся заголовки и индексные строки, сохранив при этом «нормальные» контексты с упоминанием этнонимов.

**Ядро фильтра — позиционная дедупликация:**  
- Текст предложения нормализуется: нижний регистр, удаление цифр и части пунктуации, опционально лемматизация и обрезка до 15 лемм; стоп-слова удаляются.  
- Позиция в документе квантуется: **position_bucket** (именованные зоны: начало/ранняя/середина/поздняя/конец) и **position_bucket_pct** с шагом 2% (0, 2, 4, … 100).  
- Правила:
  - Один и тот же нормализованный текст на одной и той же позиционной корзине (**sentence_norm**, **position_bucket_pct**) повторяется в документе ≥ **K** раз (по умолчанию K=2) → строка помечается как **is_position_header_footer**.  
  - Тот же (sentence_norm, position_bucket_pct) встречается в ≥ **N_cross_doc** документах (по умолчанию 3) → **is_cross_doc_header_footer**.  
  - Глобальный повтор ≥ **M** раз (по умолчанию M=5) по всему корпусу → **is_global_repeat**.

**Дополнительные маркеры (regex/шаблоны):**  
- Строки, похожие на номера страниц, глав, римские цифры, элементы оглавления («THE WEDDING 17», списки страниц и т.п.) → **is_probable_header_footer**.  
- Итоговый флаг **is_noise** = True, если выполнено хотя бы одно из: is_position_header_footer, is_cross_doc_header_footer, is_global_repeat, is_probable_header_footer. В колонке **noise_reason** сохраняется причина.

**Результат:**  
- **raw_df** — все строки mentions_df с добавленными колонками нормализации и флагами шума.  
- **clean_df** = raw_df[~raw_df["is_noise"]] — выборка без шума; именно она используется для PIRO, нормировок, keyness, сетей и индексов.

Параметры (K_position, M_global, N_cross_doc, repeat_threshold) фиксируются в **паспорте прогона** (run_passport) и записываются в `output/metadata/run_passport.json`.

---

## 6. PIRO-разметка (P, R, O, эссенциализация)

Для каждой строки **clean_df** (и отдельно для raw_df при экспорте «сырых» фрагментов) строится запись PIRO.

**P (Person):** канонический этноним из упоминания (`ethnos_norm` / P). Вариант написания в тексте сохраняется как `ethnos_raw` / `mention`.

**Эпитеты:** извлекаются из окрестности этнонима в предложении (окно слов, при наличии зависимостей — по синтаксису). Используются при подсчёте репрезентации (R): совпадение эпитета с лексиконом даёт повышенный вес (1.2 против 1.0 для слова в контексте).

**R (Representation) — тип репрезентации:**  
- **Лексикон:** `resources/representation_lexicons.yml` — три списка маркеров: **negative**, **exotic**, **positive**.  
- **Алгоритм:** по контексту (и при необходимости по леммам контекста) и эпитетам считаются три скора: score_negative, score_exotic, score_positive (каждое совпадение с лексиконом даёт 1.0, совпадение в эпитетах — 1.2).  
- **Назначение категории:** выбирается категория с максимальным скором. Если разница между первым и вторым скором меньше порога **delta_uncertain** (по умолчанию 1), назначается **uncertain**. Если максимальный скор ≤ 0 — **neutral**.  
- **Выход:** R ∈ {negative, exotic, positive, neutral, uncertain}, плюс R_scores, R_confidence.

**O (Occasion / ситуация) — тип дискурсивной сцены:**  
- **Лексикон:** `resources/situation_domains.yml` — домены (military, trade, everyday_life, descriptive_scene, religion, diplomacy и т.д.) и списки маркеров-слов.  
- **Алгоритм:** по контексту (или по леммам) считается число совпадений с маркерами каждого домена. Если нет совпадений или максимальный скор ниже порога — **unknown**. Если второй по величине скор достаточно близок к первому (≥ 0.6 от первого) — **mixed**. Иначе присваивается домен с максимальным скором.  
- **Выход:** O_situation (имя домена или unknown/mixed), O_scores, O_confidence.

**Эссенциализация:**  
- **Паттерны** (regex): «The X are …», «X are …», «all X», «X as a race/people/tribe», «X by nature», «X tend to», «X are prone/apt to», «invariably/always» рядом с X, «X, who …» и др. (см. `src/essentialization.py`).  
- Для каждого предложения проверяется наличие паттерна; при этом захваченное слово X может быть сверено с вариантами этнонима из словаря.  
- **Выход:** is_essentializing (bool), essentialization_pattern (имя паттерна), essentialization_span (фрагмент текста).

**Итоговая запись PIRO** содержит также: file_name, sent_idx, sentence_text, context_text, O_metadata (file, sentence_index), флаги и причины шума (если считали по raw_df), token_count. Все такие записи по **clean_df** образуют **piro_clean**; по **raw_df** — **piro_raw**.

---

## 7. Нормировка на 10 000 предложений

Чтобы сделать сопоставимыми документы разной длины, частоты приводятся к базе **10 000 предложений** в рамках каждого документа.

**Формула нормированной частоты (rate per 10k):**  
Для документа с числом предложений `S` и числом упоминаний (по выбранной группе: этнос, R, O) `C`:

```
rate_per_10k = (C / S) * 10 000
```

**Агрегация по корпусу:** для каждой группы (этнос, тип R, тип O) считаются:  
- суммарное количество упоминаний по всем документам;  
- по каждому документу — rate_per_10k; затем **среднее** и **медиана** этих rate по документам, при необходимости — bootstrap 95% CI для среднего.  
Реализация: `src/normalization.py` (counts_by_doc, rates_per_10k, aggregate_rates, normalized_stats_ethnos, normalized_stats_R, normalized_stats_O).

В отчёте графики и таблицы могут отображаться в режиме «сырые частоты» или «нормированные (на 10k предл.)»; единый стандарт для сопоставлений — нормировка на 10k.

---

## 8. Keyness (ключевые слова)

**Назначение:** выявить слова, статистически значимо более частые в подкорпусе (например, в контекстах с негативной репрезентацией или в контекстах упоминания конкретного этноса) по сравнению с референсным подкорпусом.

**Статистика:** **G2 (Dunning’s log-likelihood).** Для слова *w*:  
- *w_focus*, *w_ref* — частоты *w* во фокус- и референс-корпусе;  
- *n_focus*, *n_ref* — объёмы корпусов в токенах.  
Ожидаемые частоты:  
- *e1* = n_focus × (w_focus + w_ref) / (n_focus + n_ref),  
- *e2* = n_ref × (w_focus + w_ref) / (n_focus + n_ref).  

Тогда:

```
G2 = 2 × ( w_focus × ln(w_focus/e1) + w_ref × ln(w_ref/e2) )
```

(считается только при e1, e2 > 0; иначе G2 = 0). Дополнительно считается **log_ratio** (effect size) с сглаживанием prior.

**Режимы:**  
- По типу репрезентации (R): фокус — контексты с данным R, референс — остальные.  
- По этносу: фокус — контексты упоминания данного этнонима, референс — остальные.

**Фильтры:**  
- Только контентные слова (NOUN, ADJ, VERB) при наличии spaCy и pos_mode="content_words".  
- Минимальная длина слова (KEYNESS_MIN_WORD_LEN = 3), отсечение стоп-слов и эвристика OCR-мусора (повторы букв, 4+ согласных подряд и т.п.).  
- Минимальная частота во фокусе: min_freq_focus (по умолчанию 2).

**Выход:** таблицы (DataFrame) с колонками: **word**, **freq_focus**, **freq_ref**, **G2**, **log_ratio**; сортировка по G2 по убыванию. Таблицы сохраняются в `output/tables/`; в отчёте выводятся топ-N слов и при наличии Evidence — **KWIC** (контексты с указанием source_pointer) для верификации.

---

## 9. Сети: co-mention и interaction

**Co-mention (совместное упоминание):**  
- Контекст = ±2 предложения вокруг предложения с упоминанием.  
- В одном контексте извлекаются все канонические этнонимы; пары (a, b), a ≠ b, считаются один раз на контекст.  
- **Raw:** матрица пар (a, b) с весами = число контекстов, в которых оба встретились.  
- **Jaccard:** для каждой пары (a, b) — |контексты, содержащие и a, и b| / |контексты, содержащие a или b|.

**Interaction (направленная сеть по глаголам):**  
- **Словарь:** `resources/interaction_verbs.yml` — группы глаголов (например, conflict, trade, governance) и списки лемм/форм.  
- В предложениях с минимум 5 токенами, с долей букв ≥ 0.5 и без индексных шаблонов ищутся глаголы из словаря. По синтаксическим зависимостям (nsubj/nsubjpass, dobj/pobj) определяются субъект и объект; при необходимости субъект/объект сопоставляются с этнонимами в предложении.  
- Ребро: **subject_ethnonym → object_ethnonym** с типом = группа глагола; вес = количество таких пар.  
- **Выход:** список рёбер {src, dst, type, count, examples} и матрица для визуализации.  

**Ограничение метода:** разрежённость графа interaction может быть следствием узкого набора глаголов и жёстких правил извлечения SVO, а не реального отсутствия взаимодействий в текстах. Это явно указывается в разделе «Методологические ограничения» отчёта.

---

## 10. Производные индексы ориентализации

Все индексы считаются по **очищенной выборке** (piro_clean) и при необходимости по **mentions_per_ethnos** (число упоминаний по каждому каноническому этнониму).

**OI (Orientalization Index)**  
- Определение: доля упоминаний с **негативной** или **экзотизирующей** репрезентацией среди всех упоминаний по данному этносу.  
- Формула: для этноса *e*, с числами *n_neg*, *n_exo*, *n_total* по piro_clean:

```
OI(e) = (n_neg + n_exo) / n_total
```

- Дополнительно: **bootstrap 95% CI** для OI (по 500 сэмплам с возвратом из бинарного вектора «1 = negative или exotic, 0 = иначе»).  
- В отчёте: raw_OI, normalized_OI (если используется нормированная база), confidence_interval (low, high).

**ED (Essentialization Degree)**  
- Определение: доля упоминаний с эссенциализирующей конструкцией среди всех упоминаний по этносу.  
- Формула: essentialization_table[ethnos] / mentions_per_ethnos[ethnos] (при нулевом знаменателе ED = 0).

**EPS (Evaluative Polarity Score)**  
- Определение: перекос «негатив минус позитив» в репрезентации.  
- Формула:

```
EPS(e) = (n_negative - n_positive) / n_total
```

**AS (Agency Score)**  
- Определение: асимметрия ролей в сети interaction — насколько этнос чаще выступает субъектом действия (исходящие рёбра), чем объектом (входящие).  
- По каждому узлу: out_degree = сумма весов исходящих рёбер, in_degree = сумма весов входящих.  
- Формула:

```
AS(node) = (out_degree - in_degree) / (out_degree + in_degree)
```

(при нулевой сумме AS = 0).  
- Интерпретация: AS > 0 — группа чаще субъект; AS < 0 — чаще объект в контекстах взаимодействия.

**Надёжность:** при **N < 20** упоминаний по этносу индексы считаются статистически неустойчивыми; в таблице индексов и в методическом разделе делается пометка «низкая надёжность» и рекомендуется не строить выводы уровня статьи без дополнительной проверки или явного указания ограничения.

---

## 11. Второй аналитический слой (derived analytics)

При включённом шаге **8c** (по умолчанию включён, отключение: `--no-derived`) поверх piro_clean и индексов строятся:

- **Профили этносов:** таблица с полями mentions_raw, mentions_norm (на 10k), OI, ED, EPS, AS, доли uncertain_R, unknown_O, noise_share, а также дельты (OI_delta, ED_delta и т.д.) относительно взвешенного среднего по корпусу.  
- **Статистические проверки:** Chi-square для таблиц сопряжённости Ethnos×R и Ethnos×O; **Cramér's V**; **bootstrap 95% CI** по топ-этносам для OI, ED, EPS.  
- **Корреляции:** Pearson и Spearman между OI, ED, EPS, AS, mentions_norm (сохранение в `output/derived/correlations.csv`).  
- **Кластеры:** KMeans по признакам (OI, ED, EPS, AS), выбор числа кластеров по silhouette; результат в `output/derived/` и в таблицах ethnic_profiles.

Эти артефакты не изменяют corpus.db и pipeline.db; они предназначены для углублённого анализа и для раздела «Профиль этноса» в отчёте.

---

## 12. Выходные данные и артефакты

**Паспорт прогона (run_passport):**  
- Дата/время, список входных документов, число документов и предложений, n_raw, n_clean, n_noise, noise_pct, параметры фильтра шума (repeat_threshold, K_position, M_global, N_cross_doc).  
- Сохраняется в `output/metadata/run_passport.json`; выводится в начале report.html и scientific_report.html как единый источник цифр прогона.

**Кэш пайплайна (pipeline.db):**  
- Корпус (предобработанный), raw_df, clean_df, piro_raw, piro_clean, norm_ethnos, norm_R, norm_O, keyness_tables, essentialization_table, essentialization_examples, interaction_edges, comention_raw, derived_indices. Используется при запуске с `--from-db` для повторной сборки отчёта без пересчёта шагов 1–8b.

**Индексы:**  
- `output/derived_indices.json`: OI (raw_OI, normalized_OI, confidence_interval), AS, ED, EPS, mentions_per_ethnos.

**Отчёты:**  
- **report.html** — интерактивный отчёт: паспорт прогона, распределения (этносы, R, O), варианты написания этнонимов, keyness с KWIC, эссенциализация, сети, таблица индексов (N, надёжность, CI), Evidence Pack, научный текст ИИ (если сгенерирован), синтез, методологические ограничения, токены LLM.  
- **scientific_report.html** — плотный аналитический текст по секциям (корпус, распределения, keyness, эссенциализация, сети, индексы, профили, заключение), с паспортом прогона, блоками «Проверка» (ссылки на report.html) и «Доказательная база» (примеры с source_pointer), а также разделом «Методологические ограничения».

**Экспорты для верификации и статей:**  
- **evidence_base.xlsx** — два листа: **evidence_clean** (записи, вошедшие в отчёт) и **excluded_noise** (исключённые с noise_reason). Колонки включают source_pointer, P, R, O, sentence_text и флаги шума.  
- **piro_fragments.xlsx** — полный набор полей PIRO по сырой и очищенной выборке.  
- **output/tables/** — CSV/таблицы keyness по подкорпусам; **output/figures/** — графики, сети, UMAP при включённых embeddings.

**Keyness и доказательность:**  
- В report.html для каждого подкорпуса keyness выводятся таблица топ-N слов (word, G2, freq_focus) и при наличии данных Evidence — раскрывающийся блок **KWIC** (до 3 примеров контекста на слово с source_pointer). В научном отчёте интерпретация keyness опирается на «таблицы keyness и KWIC-примеры» в report.html.

---

## 13. Методологические ограничения (кратко)

- **Единица наблюдения:** одно упоминание в контексте предложения; агрегация по каноническому этнониму.  
- **N < 20:** индексы OI, ED, EPS, AS для таких этносов ненадёжны; в отчёте помечаются.  
- **Keyness:** пороги частоты, G2, лемматизация и фильтр OCR заданы в пайплайне; интерпретация должна опираться на таблицы и KWIC.  
- **Сети interaction:** разрежённость может быть следствием словаря глаголов и правил извлечения SVO.  
- **R и O:** классификация по лексиконам (и опционально LLM); возможны пропуски и шум.  
- **Корпус и шум:** состав документов и параметры фильтра задают границы репрезентативности; верификация по source_pointer и evidence_base.xlsx рекомендуется для ключевых выводов.

---

## 14. Ссылки на ключевые файлы кода и ресурсов

| Компонент | Файл / ресурс |
|-----------|----------------|
| Пайплайн, паспорт прогона | `main.py` |
| Этнонимы, извлечение упоминаний | `resources/ethnonyms.yml`, `src/ethnonym_extractor.py` |
| Фильтр шума | `src/noise_filter.py` |
| PIRO, R, O, эссенциализация | `src/piro.py`, `src/representation_classifier.py`, `src/situation_classifier.py`, `src/essentialization.py` |
| Лексиконы R и O | `resources/representation_lexicons.yml`, `resources/situation_domains.yml` |
| Нормировка | `src/normalization.py` |
| Keyness | `src/keyness.py` |
| Сети | `src/relations.py`, `resources/interaction_verbs.yml` |
| Индексы OI, AS, ED, EPS | `analysis/derived_indices.py` |
| Профили, тесты, кластеры | `analysis/derived_analytics.py` |
| Сборка отчётов | `reports/build_report.py`, `llm/scientific_report.py` |
| Экспорт Evidence | `exporters/export_excel.py` |

Этот документ можно цитировать в методических разделах статей как описание платформы и формул расчёта.
